{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c172777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import networkx\n",
    "from nltk import edit_distance\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b177f3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220244, 5),\n",
       "                             index     2\n",
       " 0     AGAAGAACTAATGTTAGTATAAGTAAC  4578\n",
       " 1     GAGCCTGGTGATAGCTGGTTGTCCAAG  4219\n",
       " 2     CGCATAAGCCTGCGTCAGATTAAAACA  4179\n",
       " 3     CTCCTCACACCCAATTGGACCAATCTA  3829\n",
       " 4     ATTGGACCAATCTATCACCCTATAGAA  3807\n",
       " ...                           ...   ...\n",
       " 1321  TGGAATTCTTTGTCTTTGACTTTTGAC     2\n",
       " 1322  AGCGTGGCCGTTGGCTGCCTCGCACAG     2\n",
       " 1323  CCGACGGCACCTACGGCTCAACATTTT     2\n",
       " 1324  GCTCATATGCGAGCGCTAATTCTGTGG     2\n",
       " 1325  CTCAGGGAGTGCATCCGCCCCAACCCT     2\n",
       " \n",
       " [1326 rows x 2 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satcs = glob.glob('*_2/*')\n",
    "satc_ = pd.read_csv('tabula_sapiens_10x_unpacked_2/TSP_10x_gap_0_unpublished_SPLIT_TSP21_SPLIT_BoneMarrowbin88.satc_unpacked',sep='\\t',header=None)\n",
    "satc_ = satc_[satc_[4]>1]\n",
    "satc = satc_[satc_[2]=='AGAAGAACTAATGTTAGTATAAGTAAC']\n",
    "satc_.shape, satc_[2].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b13d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "satc = satc.rename(columns={1:'sample',2:'anchor',3:'target',4:'count'})\n",
    "satc = satc[['sample','anchor','target','count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a4fb0",
   "metadata": {},
   "source": [
    "### Define configurations for a target-centered graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a75231",
   "metadata": {},
   "source": [
    "\n",
    "graphName : (anchor, class)\n",
    "\n",
    "nodeType : \"target\" \n",
    "\n",
    "nodeFeatures : [ \"seqComp\" , \"sampleFraction\" ]\n",
    "\n",
    "edgeFeatures : [ \"targetHamming\" , \"targetLevenshtein\" , \"corrSampleFractions\" , \n",
    "                 \"corrBoolSampleFractions\" , \"naiveMSA\" ]\n",
    "\n",
    "connectedness: [ \"full\" , \"sampleCorrelated\" , \"toleratedHamming_\"+{float} , \"toleratedLevenshtein_\"+{float} ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea4f7f",
   "metadata": {},
   "source": [
    "### Define configurations for a sample-centered graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b8534",
   "metadata": {},
   "source": [
    "graphName : (anchor, class)\n",
    "\n",
    "nodeType : \"sample\" \n",
    "\n",
    "nodeFeatures : [ \"maskedSeqComp\" , \"sampleFraction\" ]\n",
    "\n",
    "edgeFeatures : [ \"fullTargetHamming\" , \"fullTargetLevenshtein\" ,\"aggTargetHamming\" , \"aggTargetLevenshtein\" ,\n",
    "                 \"corrSampleFractions\" ,  \"corrBoolSampleFractions\" , \"naiveMSA\" ]\n",
    "\n",
    "connectedness: [ \"full\" , \"sampleCorrelated\" , \"toleratedMeanHamming_\"+{float} , \"toleratedMeanLevenshtein_\"+{float} ] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd71862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_featurization(data, nodeType, nodeFeatures, ordering):\n",
    "    \n",
    "    nodeFeatureDict = dict()\n",
    "    \n",
    "    if 'seqComp' in nodeFeatures:\n",
    "        \n",
    "        nodeFeatureDict['seqComp'] = dict()\n",
    "        \n",
    "        for target in data['target'].unique():\n",
    "        \n",
    "            seq = np.array(list(target))\n",
    "            mat = np.zeros(shape=(4,len(seq)))\n",
    "            mat[0] = np.array([1*(seq == 'A')])\n",
    "            mat[1] = np.array([1*(seq == 'C')])\n",
    "            mat[2] = np.array([1*(seq == 'G')])\n",
    "            mat[3] = np.array([1*(seq == 'T')])\n",
    "            nodeFeatureDict['seqComp'][target] = mat\n",
    "            \n",
    "    if 'sampleFraction' in nodeFeatures:\n",
    "    \n",
    "        nodeFeatureDict['sampleFraction'] = dict()\n",
    "        \n",
    "        if nodeType == 'sample':\n",
    "            \n",
    "            full = pd.DataFrame({'target':ordering})\n",
    "            \n",
    "            for sample in data['sample'].unique():\n",
    "                \n",
    "                this_full = full.merge(data[data['sample']==sample][['target','count']],how='left').fillna(0)\n",
    "                nodeFeatureDict['sampleFraction'][sample] = np.array(this_full['count'] / this_full['count'].sum())\n",
    "        \n",
    "        if nodeType == 'target': \n",
    "          \n",
    "            full = pd.DataFrame({'sample':ordering})\n",
    "            \n",
    "            for target in data['target'].unique():\n",
    "                \n",
    "                this_full = full.merge(data[data['target']==target][['target','count']],how='left').fillna(0)\n",
    "                nodeFeatureDict['sampleFraction'][target] = np.array(this_full['count'] / this_full['count'].sum())\n",
    "             \n",
    "\n",
    "    if 'maskedSeqComp' in nodeFeatures:\n",
    "     \n",
    "        if 'seqComp' in nodeFeatures:\n",
    "            internalFeatureDict = nodeFeatureDict\n",
    "        \n",
    "        else:\n",
    "            internalFeatureDict = dict()\n",
    "        \n",
    "        for target in data['target'].unique():\n",
    "         \n",
    "            seq = np.array(list(target))\n",
    "            mat = np.zeros(shape=(4,len(seq)))\n",
    "            mat[0] = np.array([1*(seq == 'A')])\n",
    "            mat[1] = np.array([1*(seq == 'C')])\n",
    "            mat[2] = np.array([1*(seq == 'G')])\n",
    "            mat[3] = np.array([1*(seq == 'T')])\n",
    "            internalFeatureDict['seqComp'][target] = mat\n",
    "        \n",
    "        for sample in data['sample'].unique():\n",
    "               \n",
    "            nodeFeatureDict['maskedSeqComp'][sample] = np.zeros(shape=(len(ordering),4,len(ordering[0])))\n",
    "            sample_targets = set(data[data['sample']==sample]['target'].unique())\n",
    "            ordering_set = set(ordering)\n",
    "            \n",
    "            for index in range(len(ordering)):\n",
    "                \n",
    "                verbose = ordering[index]\n",
    "                \n",
    "                if verbose in sample_targets:\n",
    "                    \n",
    "                    nodeFeatureDict['maskedSeqComp'][sample][index] = internalFeatureDict['seqComp'][verbose]\n",
    "        \n",
    "    return nodeFeatureDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aab80e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_similarities(values, function):\n",
    "    \n",
    "    distanceMatrix = np.zeros(shape=(len(values),len(values)))\n",
    "\n",
    "    for i in range(len(values)): \n",
    "\n",
    "        for j in range(len(values)):\n",
    "\n",
    "            distanceMatrix[i][j] = function(values[i], values[j])\n",
    "    \n",
    "    return distanceMatrix\n",
    "\n",
    "\n",
    "def hamming_distance(seq1, seq2):\n",
    "    \n",
    "    return sum(c1 != c2 for c1, c2 in zip(seq1, seq2))\n",
    "\n",
    "\n",
    "def correlation_matrix(vectorDict, keys, isBoolMasked):\n",
    "    \n",
    "    correlationMatrix = np.zeros(shape=(len(keys),len(keys)))\n",
    "    setList = []\n",
    "\n",
    "    if not isBoolMasked:\n",
    "    \n",
    "        for i in range(len(keys)): \n",
    "\n",
    "            for j in range(len(keys)): \n",
    "            \n",
    "                corr = np.dot(vectorDict[keys[i]], vectorDict[keys[j]])\n",
    "                correlationMatrix[i][j] = corr\n",
    "                \n",
    "                if corr > 0: \n",
    "                    \n",
    "                    s = set([keys[i],keys[j]])\n",
    "                    \n",
    "                    if len(s) > 1 and s not in setList:\n",
    "                        \n",
    "                        setList.append(s)\n",
    "        \n",
    "        return correlationMatrix, [tuple(i) for i in setList]\n",
    "    \n",
    "    if isBoolMasked: \n",
    "        \n",
    "        for i in keys: \n",
    "            \n",
    "            for j in keys: \n",
    "                \n",
    "                correlationMatrix[i][j] = np.dot((1*(vectorDict[i]>0)), (1*(vectorDict[j]>0)))\n",
    "    \n",
    "        return correlationMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38c562b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(data, graphName, nodeType, nodeFeatures, edgeFeatures, connectedness, ordering):\n",
    "    \n",
    "    output_dict = dict()\n",
    "    \n",
    "    output_dict['nodeFeatures'] = node_featurization(data, nodeType, nodeFeatures, ordering)\n",
    "    \n",
    "    if nodeType == 'target': \n",
    "        \n",
    "        node_value_arr = data['target'].unique()\n",
    "        \n",
    "    if nodeType == 'sample': \n",
    "        \n",
    "        node_value_arr = data['sample'].unique()\n",
    "        \n",
    "    ####\n",
    "    ####\n",
    "    ####\n",
    "    #### If needed, precompute all pairwise Hamming and/or Levenshtein distances.\n",
    "        \n",
    "    hamDistanceMatrix = 0\n",
    "    \n",
    "    if 'Hamming' in ''.join(edgeFeatures) or ''.join(connectedness):\n",
    "        \n",
    "        if nodeType == 'target': \n",
    "            \n",
    "            hamDistanceMatrix = pairwise_similarities(node_value_arr, hamming_distance)\n",
    "        \n",
    "        if nodeType == 'sample': \n",
    "            \n",
    "            hamDistanceMatrix = pairwise_similarities(ordering, hamming_distance)\n",
    "            \n",
    "    levDistanceMatrix = 0\n",
    "        \n",
    "    if 'Levenshtein' in ''.join(edgeFeatures) or ''.join(connectedness):\n",
    "        \n",
    "        if nodeType == 'target': \n",
    "            \n",
    "            levDistanceMatrix = pairwise_similarities(node_value_arr, edit_distance)\n",
    "            \n",
    "        if nodeType == 'sample': \n",
    "            \n",
    "            levDistanceMatrix = pairwise_similarities(ordering, edit_distance)\n",
    "            \n",
    "    ####\n",
    "    ####\n",
    "    ####\n",
    "    #### Define edge sets prior to constructing edge features. \n",
    "    \n",
    "    if 'full' in connectedness: \n",
    "        \n",
    "        output_dict['edges'] = list(combinations(node_value_arr, 2))\n",
    "        \n",
    "    correlationMatrix = 0\n",
    "    \n",
    "    if 'sampleCorrelated' in connectedness or 'corr' in ''.join(edgeFeatures): \n",
    "        \n",
    "        correlationMatrix, output_dict['edges'] = correlation_matrix(output_dict['nodeFeatures'][nodeType]['sampleFraction'], node_value_arr, False)\n",
    "        \n",
    "    boolcorrelationMatrix = 0\n",
    "    \n",
    "    if 'Bool' in ''.join(edgeFeatures):\n",
    "\n",
    "        boolCorrelationMatrix = correlation_matrix(output_dict['nodeFeatures'][nodeType]['sampleFraction'], node_value_arr, True)   \n",
    "    \n",
    "    output_dict['edgeFeatures'] = edgeFeatures(data, nodeType, edges, edgeFeatures, node_value_arr, ordering, hamDistanceMatrix, levDistanceMatrix, correlationMatrix, boolCorrelationMatrix)\n",
    "            \n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0963615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeFeatures(data, nodeType, edgeFeatures, nodeFeatures, nodeOrdering, ordering, hamDistanceMatrix, levDistanceMatrix, correlationMatrix, boolCorrelationMatrix):\n",
    "    \n",
    "    edgeFeatureDict = dict()\n",
    "        \n",
    "    for edge in edges: \n",
    "\n",
    "        i, j = np.nonzero(nodeOrdering==edge[0]), np.nonzero(nodeOrdering==edge[1])\n",
    "        edgeFeatureDict[edge] = dict()\n",
    "\n",
    "        if 'corrBoolSampleFractions' in edgeFeatures:\n",
    "            \n",
    "            edgeFeatureDict[edge]['corrBoolSampleFractions'] = boolCorrelationMatrix[i][j]\n",
    "        \n",
    "        if 'corrSampleFractions' in edgeFeatures:\n",
    "            \n",
    "            edgeFeatureDict[edge]['corrBoolSampleFractions'] = correlationMatrix[i][j]\n",
    "            \n",
    "        if 'targetHamming' in edgeFeatures:\n",
    "            \n",
    "            edgeFeatureDict[edge]['targetHamming'] = hamDistanceMatrix[i][j]\n",
    "            \n",
    "        if 'targetLevenshtein' in edgeFeatures:\n",
    "            \n",
    "            edgeFeatureDict[edge]['targetLevenshtein'] = levDistanceMatrix[i][j]\n",
    "            \n",
    "    return edgeFeatureDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6cce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
